{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6fed3ab1",
   "metadata": {},
   "source": [
    "# Open Food Facts â€” Project Loader & Column Drop (CSV only)\n",
    "\n",
    "Loads the dataset from `../data/openfoodfacts/en.openfoodfacts.org.products.csv` using a tolerant parser,\n",
    "drops predefined empty/useless columns, and prints the remaining schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02baf702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Project-correct path (CSV only) ---\n",
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = (Path.cwd().resolve() / \"..\" / \"data\" / \"openfoodfacts\" / \"en.openfoodfacts.org.products.csv\")\n",
    "INPUT_FILE_NAME = str(DATA_PATH)\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    raise FileNotFoundError(f\"Dataset not found: {DATA_PATH}\")\n",
    "print(\"Resolved path ->\", INPUT_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73c6b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Robust load (python engine, skips malformed rows) ---\n",
    "import pandas as pd, csv\n",
    "\n",
    "# Optional LIMIT to load only first N rows for speed; set to None to read all\n",
    "LIMIT = None\n",
    "nrows = LIMIT if (isinstance(LIMIT, int) and LIMIT > 0) else None\n",
    "\n",
    "df = pd.read_csv(\n",
    "    INPUT_FILE_NAME,\n",
    "    sep=\"\\t\",                 # OFF \"csv\" is tab-separated\n",
    "    engine=\"python\",          # tolerant parser for messy lines\n",
    "    on_bad_lines=\"skip\",      # skip malformed rows\n",
    "    dtype=\"string\",\n",
    "    na_values=[\"\", \" \", \"NA\", \"N/A\", \"null\", \"NULL\"],\n",
    "    keep_default_na=True,\n",
    "    quoting=csv.QUOTE_MINIMAL,\n",
    "    escapechar=\"\\\\\",\n",
    "    # NOTE: low_memory is NOT supported with python engine; do not pass it\n",
    ")\n",
    "\n",
    "print(f\"Loaded rows: {len(df):,}; columns: {len(df.columns):,}\")\n",
    "display(df.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e20af14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Drop specified empty/useless columns ---\n",
    "to_drop = ['additives', 'allergens_en', 'capric-acid_100g', 'carbohydrates-total_100g', 'cities', 'isomalt_100g', 'maltitol_100g', 'methylsulfonylmethane_100g', 'nutrition-score-uk_100g', 'psicose_100g', 'sorbitol_100g', 'caprylic-acid_100g', 'galactose_100g', 'nervonic-acid_100g', 'water-hardness_100g', 'acidity_100g', 'chlorophyl_100g', 'elaidic-acid_100g', 'lauric-acid_100g', 'caproic-acid_100g', 'cerotic-acid_100g', 'gamma-linolenic-acid_100g', 'glycemic-index_100g', 'erucic-acid_100g', 'montanic-acid_100g', 'url', 'creator', 'created_t', 'last_modified_t', 'last_modified_datetime', 'last_modified_by', 'last_updated_t', 'last_updated_datetime']\n",
    "existing = [c for c in to_drop if c in df.columns]\n",
    "before = len(df.columns)\n",
    "df = df.drop(columns=existing, errors=\"ignore\")\n",
    "after = len(df.columns)\n",
    "print(f\"Dropped {len(existing)} columns. Columns before: {before}, after: {after}\")\n",
    "if existing:\n",
    "    print(\", \".join(existing))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9351a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- List all remaining column names ---\n",
    "print(\"Total columns:\", len(df.columns))\n",
    "for c in df.columns:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ca7aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Normalize date formats & columns (safe, regex-enabled) ---\n",
    "import re\n",
    "import pandas as pd\n",
    "\n",
    "if 'df' not in globals():\n",
    "    raise NameError(\"DataFrame 'df' is not defined. Run the loader cell first.\")\n",
    "\n",
    "# Strategy: match any column ending with '_datetime' and coerce to ISO UTC.\n",
    "# You can add more entries (e.g., numeric columns) by extending this list.\n",
    "strategy = [\n",
    "    {\"colname\": r\".*_datetime$\", \"dtype\": \"datetime\", \"filler\": \"1970-01-01T00:00:00Z\"},\n",
    "    # Example numeric normalization (uncomment to use):\n",
    "    # {\"colname\": r\"^energy_100g$\", \"dtype\": \"float\", \"filler\": 0.0},\n",
    "]\n",
    "\n",
    "# Ensure all columns are strings before type ops; preserves original text if needed\n",
    "for col in df.columns:\n",
    "    try:\n",
    "        df[col] = df[col].astype(\"string\")\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Apply normalization per provided logic\n",
    "for col in df.columns:\n",
    "    print(f\"colname [{col}]:\")\n",
    "    for s in strategy:\n",
    "        # Match by regex (supports '*' style via regex pattern in s['colname'])\n",
    "        if \"*\" in s[\"colname\"]:\n",
    "            # For safety: treat '*' as literal wildcard -> convert to regex '.*'\n",
    "            pattern = s[\"colname\"].replace(\"*\", \".*\")\n",
    "            m = re.search(pattern, col)\n",
    "            if m is None:\n",
    "                continue\n",
    "            print(f\"\\t[{col}] matches <{s['colname']}>.\")\n",
    "        else:\n",
    "            m = re.search(s[\"colname\"], col)\n",
    "            if m is None:\n",
    "                continue\n",
    "            print(f\"\\t[{col}] matches <{s['colname']}>.\")\n",
    "\n",
    "        df_c1 = df[col]\n",
    "        replace_complete = False\n",
    "\n",
    "        if s[\"dtype\"] == \"datetime\":\n",
    "            print(f\"\\t[{col}] is converted astype <datetime>.\")\n",
    "            while True:\n",
    "                try:\n",
    "                    # Expect ISO UTC 'YYYY-MM-DDTHH:MM:SSZ'\n",
    "                    df_c1 = pd.to_datetime(df_c1, format=\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "                    replace_complete = True\n",
    "                    break\n",
    "                except ValueError as e:\n",
    "                    m = re.search(r\"time data '([^']*)'\", str(e))\n",
    "                    if m is None:\n",
    "                        print(f\"\\t\\tUnexpected error string <{str(e)}>\")\n",
    "                        break\n",
    "                    evil_string = m.group(1).replace(\"'\", \"\")\n",
    "                    idx = df[df[col] == evil_string].index\n",
    "                    df.loc[idx, col] = s[\"filler\"]\n",
    "                    print(f\"\\t\\tReplace string <{evil_string}>[{len(idx)} rows] with <{s['filler']}>.\")\n",
    "            if replace_complete:\n",
    "                # Final cast & reformat to canonical ISO UTC\n",
    "                dt = pd.to_datetime(df_c1, errors=\"coerce\", utc=True)\n",
    "                df[col] = dt.dt.strftime(\"%Y-%m-%dT%H:%M:%SZ\")\n",
    "\n",
    "        else:\n",
    "            print(f\"\\t[{col}] is converted astype <{s['dtype']}>.\")\n",
    "            while True:\n",
    "                try:\n",
    "                    df_c1 = df_c1.astype(s[\"dtype\"], errors=\"raise\")\n",
    "                    replace_complete = True\n",
    "                    break\n",
    "                except ValueError as e:\n",
    "                    if str(e) == \"cannot convert float NaN to integer\":\n",
    "                        idx = df[df[col].isnull()].index\n",
    "                        df.loc[idx, col] = s[\"filler\"]\n",
    "                    else:\n",
    "                        m = re.search(r\"'(.*)'\", str(e))\n",
    "                        if m is not None:\n",
    "                            evil_string = m.group(1).replace(\"'\", \"\")\n",
    "                            idx = df[df[col] == evil_string].index\n",
    "                            df.loc[idx, col] = s[\"filler\"]\n",
    "                            print(f\"\\t\\tReplace string <{evil_string}>[{len(idx)} rows] with <{s['filler']}>.\")\n",
    "                        else:\n",
    "                            print(f\"\\t\\tUnexpected error string <{str(e)}>\")\n",
    "                            break\n",
    "            if replace_complete:\n",
    "                df[col] = df[col].fillna(s[\"filler\"]).astype(s[\"dtype\"])\n",
    "\n",
    "print(\"Normalization complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
